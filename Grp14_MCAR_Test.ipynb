{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d40b002",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "When working with data analysis and statistical tests, the following libraries are commonly used:\n",
    "\n",
    "### pandas\n",
    "- **Purpose**: Used for data manipulation and analysis. It provides powerful data structures (like DataFrames) for reading and processing datasets, such as `.csv` files.\n",
    "  \n",
    "### numpy\n",
    "- **Purpose**: Provides support for numerical operations and array manipulations. It is used to manipulate masks of missing values effectively.\n",
    "\n",
    "### scipy.stats import chi2\n",
    "- **Purpose**: Imports the chi-square distribution from the `scipy` library. It is utilized for calculating the chi-square statistic and the corresponding p-value in statistical tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f186b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce60427",
   "metadata": {},
   "source": [
    "### Loading a CSV File into a Pandas DataFrame\n",
    "\n",
    "Using `pd.read_csv`, we can easily load a CSV file into a pandas DataFrame. This function reads the CSV file and creates a DataFrame that allows for efficient data manipulation and analysis.\n",
    "\n",
    "**Key Points**:\n",
    "- **Function**: `pd.read_csv(filepath)`\n",
    "- **Parameters**:\n",
    "  - `filepath`: The path to the CSV file you want to load.\n",
    "  - Additional parameters can be used to customize the loading process (e.g., `delimiter`, `header`, `na_values`).\n",
    "\n",
    "This method is essential for importing data from external sources for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98309c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('startup_funding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439cf6c",
   "metadata": {},
   "source": [
    "### Retrieving Null Value Counts in a DataFrame\n",
    "\n",
    "Using `df.isnull().sum()`, we can easily retrieve the number of null values present in each column of a pandas DataFrame. \n",
    "\n",
    "**Key Points**:\n",
    "- **Function**: `df.isnull().sum()`\n",
    "  - `df.isnull()`: Creates a boolean DataFrame indicating `True` for null values and `False` for non-null values.\n",
    "  - `.sum()`: Sums up the `True` values (which are treated as 1) for each column, resulting in the total count of null values.\n",
    "\n",
    "This method is useful for assessing the completeness of data in each column before performing further analysis or data cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42867046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          936\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD          847\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ed660",
   "metadata": {},
   "source": [
    "### Displaying the First 5 Rows of a Dataset\n",
    "\n",
    "Using `df.head()`, we can easily display the first five rows of a pandas DataFrame. \n",
    "\n",
    "**Key Points**:\n",
    "- **Function**: `df.head()`\n",
    "  - This function returns the first five rows of the DataFrame by default, allowing for a quick preview of the data.\n",
    "  - You can also specify the number of rows to display by passing an integer as an argument (e.g., `df.head(10)` for the first ten rows).\n",
    "\n",
    "This method is helpful for quickly inspecting the structure and content of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb881b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>Date</th>\n",
       "      <th>StartupName</th>\n",
       "      <th>IndustryVertical</th>\n",
       "      <th>SubVertical</th>\n",
       "      <th>CityLocation</th>\n",
       "      <th>InvestorsName</th>\n",
       "      <th>InvestmentType</th>\n",
       "      <th>AmountInUSD</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01/08/2017</td>\n",
       "      <td>TouchKin</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Predictive Care Platform</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Kae Capital</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>1,300,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>Ethinos</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Digital Marketing Agency</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Triton Investment Advisors</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>Consumer Internet</td>\n",
       "      <td>Online platform for Higher Education Services</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kashyap Deorah, Anand Sankeshwar, Deepak Jain,...</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>Zepo</td>\n",
       "      <td>Consumer Internet</td>\n",
       "      <td>DIY Ecommerce platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Kunal Shah, LetsVenture, Anupam Mittal, Hetal ...</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>500,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>Click2Clinic</td>\n",
       "      <td>Consumer Internet</td>\n",
       "      <td>healthcare service aggregator</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Narottam Thudi, Shireesh Palle</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>850,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo        Date   StartupName   IndustryVertical  \\\n",
       "0    0  01/08/2017      TouchKin         Technology   \n",
       "1    1  02/08/2017       Ethinos         Technology   \n",
       "2    2  02/08/2017  Leverage Edu  Consumer Internet   \n",
       "3    3  02/08/2017          Zepo  Consumer Internet   \n",
       "4    4  02/08/2017  Click2Clinic  Consumer Internet   \n",
       "\n",
       "                                     SubVertical CityLocation  \\\n",
       "0                       Predictive Care Platform    Bangalore   \n",
       "1                       Digital Marketing Agency       Mumbai   \n",
       "2  Online platform for Higher Education Services    New Delhi   \n",
       "3                         DIY Ecommerce platform       Mumbai   \n",
       "4                  healthcare service aggregator    Hyderabad   \n",
       "\n",
       "                                       InvestorsName  InvestmentType  \\\n",
       "0                                        Kae Capital  Private Equity   \n",
       "1                         Triton Investment Advisors  Private Equity   \n",
       "2  Kashyap Deorah, Anand Sankeshwar, Deepak Jain,...    Seed Funding   \n",
       "3  Kunal Shah, LetsVenture, Anupam Mittal, Hetal ...    Seed Funding   \n",
       "4                     Narottam Thudi, Shireesh Palle    Seed Funding   \n",
       "\n",
       "  AmountInUSD Remarks  \n",
       "0   1,300,000     NaN  \n",
       "1         NaN     NaN  \n",
       "2         NaN     NaN  \n",
       "3     500,000     NaN  \n",
       "4     850,000     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82d710",
   "metadata": {},
   "source": [
    "The `df.info()` method in pandas provides a concise summary of a DataFrame, giving essential information about its structure and contents. It is especially useful for quickly understanding the dataset you're working with.\n",
    "\n",
    "### Key Details Provided by `df.info()`:\n",
    "1. **Number of Rows and Columns**:\n",
    "   - It shows the total number of rows and columns in the DataFrame, helping you understand the size of your dataset.\n",
    "\n",
    "2. **Column Names and Data Types**:\n",
    "   - Lists all the columns in the DataFrame along with their respective data types (e.g., `int64`, `float64`, `object`, etc.). This helps in identifying potential issues with data types, such as a numeric column being stored as `object`.\n",
    "\n",
    "3. **Non-Null Count**:\n",
    "   - Displays the count of non-null values for each column. This allows you to see how much data is missing in each column without manually checking for null values.\n",
    "\n",
    "4. **Memory Usage**:\n",
    "   - Provides the memory usage of the DataFrame, which is helpful for optimizing the DataFrame’s size when working with large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca43914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2372 entries, 0 to 2371\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   SNo               2372 non-null   int64 \n",
      " 1   Date              2372 non-null   object\n",
      " 2   StartupName       2372 non-null   object\n",
      " 3   IndustryVertical  2201 non-null   object\n",
      " 4   SubVertical       1436 non-null   object\n",
      " 5   CityLocation      2193 non-null   object\n",
      " 6   InvestorsName     2364 non-null   object\n",
      " 7   InvestmentType    2371 non-null   object\n",
      " 8   AmountInUSD       1525 non-null   object\n",
      " 9   Remarks           419 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 185.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621484d",
   "metadata": {},
   "source": [
    "### Converting `AmountInUSD` to Integer Type\n",
    "\n",
    "To convert the column named `AmountInUSD` to an integer type, we need to follow these steps:\n",
    "\n",
    "1. **Replace Commas**: Since the values are stored as objects and may contain commas (e.g., \"1,000\"), we first need to replace commas with empty strings.\n",
    "2. **Fill NaN Values**: Next, we fill any NaN values with `0` to avoid errors during the conversion.\n",
    "3. **Convert to Integer**: Finally, we use the `astype()` function to convert the cleaned column to an integer type.\n",
    "\n",
    "**Key Steps**:\n",
    "- Use `df['AmountInUSD'].str.replace(\",\", \"\")` to remove commas.\n",
    "- Use `df['AmountInUSD'].fillna(0, inplace=True)` to fill NaN values.\n",
    "- Use `df['AmountInUSD'] = df['AmountInUSD'].astype(int)` to convert the column to integers.\n",
    "\n",
    "This process ensures that the `AmountInUSD` column is properly formatted for numerical analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84af14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1,300,000\n",
       "1             NaN\n",
       "2             NaN\n",
       "3         500,000\n",
       "4         850,000\n",
       "          ...    \n",
       "2367    4,500,000\n",
       "2368      825,000\n",
       "2369    1,500,000\n",
       "2370          NaN\n",
       "2371      140,000\n",
       "Name: AmountInUSD, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AmountInUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9edb425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AmountInUSD'] = df['AmountInUSD'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef03c4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1300000\n",
       "1           NaN\n",
       "2           NaN\n",
       "3        500000\n",
       "4        850000\n",
       "         ...   \n",
       "2367    4500000\n",
       "2368     825000\n",
       "2369    1500000\n",
       "2370        NaN\n",
       "2371     140000\n",
       "Name: AmountInUSD, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AmountInUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b701c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AmountInUSD'] =df['AmountInUSD'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b5b54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1300000\n",
       "1             0\n",
       "2             0\n",
       "3        500000\n",
       "4        850000\n",
       "         ...   \n",
       "2367    4500000\n",
       "2368     825000\n",
       "2369    1500000\n",
       "2370          0\n",
       "2371     140000\n",
       "Name: AmountInUSD, Length: 2372, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AmountInUSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4b2a4",
   "metadata": {},
   "source": [
    "### `df.isnull().sum()` Usage\n",
    "\n",
    "The `df.isnull().sum()` method in pandas is used to quickly identify and count the number of missing (`NaN`) values in each column of a DataFrame. This is particularly useful for checking data quality and understanding how much data is missing from each feature.\n",
    "\n",
    "#### How It Works:\n",
    "- **`df.isnull()`**: This returns a DataFrame of the same shape as `df`, with `True` where values are `NaN` and `False` otherwise.\n",
    "- **`sum()`**: When applied after `isnull()`, it counts the number of `True` values (i.e., missing values) for each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daaca436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          936\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32974c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2372"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd06291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d58b9",
   "metadata": {},
   "source": [
    "### `null_count_df = null_count.reset_index()` Usage\n",
    "\n",
    "The line `null_count_df = null_count.reset_index()` is used to convert a Series (in this case, `null_count`, which contains the count of missing values in each column) into a DataFrame, while also resetting the index. This operation is useful when you want to convert a summary of missing values into a DataFrame format for further manipulation or visualization.\n",
    "\n",
    "#### How It Works:\n",
    "1. **`null_count`**: This is typically a pandas Series (for example, the result of `df.isnull().sum()`) where the index contains column names, and the values represent the count of missing values in those columns.\n",
    "2. **`reset_index()`**: This method turns the index into a regular column, converting the Series into a DataFrame. The original index becomes the first column, and the data becomes the second column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eca9424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count_df = null_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1012c56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StartupName</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndustryVertical</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SubVertical</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CityLocation</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InvestorsName</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>InvestmentType</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AmountInUSD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Remarks</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index     0\n",
       "0               SNo     0\n",
       "1              Date     0\n",
       "2       StartupName     0\n",
       "3  IndustryVertical   171\n",
       "4       SubVertical   936\n",
       "5      CityLocation   179\n",
       "6     InvestorsName     8\n",
       "7    InvestmentType     1\n",
       "8       AmountInUSD     0\n",
       "9           Remarks  1953"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd942bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count_df['index'=='3'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718a6d3",
   "metadata": {},
   "source": [
    "### Importance of Missing Value Percentage in Terms of MCAR (Missing Completely at Random)\n",
    "\n",
    "Understanding the percentage of missing values in a dataset is crucial, particularly when considering the assumption of **MCAR (Missing Completely at Random)**. If data is MCAR, the missingness occurs independently of both observed and unobserved data, meaning it does not depend on the actual values of any variables.\n",
    "\n",
    "#### Why is Missing Percentage Important?\n",
    "\n",
    "1. **Bias in Analysis**:\n",
    "   - High percentages of missing values can lead to biased analyses, especially if the data is not MCAR. Non-MCAR missingness may depend on other variables or values, potentially distorting results.\n",
    "\n",
    "2. **MCAR Assumption**:\n",
    "   - If data is truly missing at random (MCAR), common techniques like listwise deletion or imputation generally won't introduce bias. However, the percentage of missing data matters—large amounts of missingness reduce the effective sample size and may affect model accuracy.\n",
    "\n",
    "3. **Data Quality**:\n",
    "   - The percentage of missing data gives a measure of the dataset's quality and reliability. If key columns have high missing percentages, additional investigation may be necessary to determine the cause and the best method for handling it.\n",
    "\n",
    "Understanding the percentage of missing values helps to decide on the right approach for handling them, depending on whether the MCAR assumption holds true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "053a4546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of value of missing in Investment column is 0.042158516020236084\n",
      "% of value of missing in Remarks column is 82.33558178752108\n",
      "% of value of missing in IndustryVerical column is 7.209106239460371\n",
      "% of value of missing in subVertical column is 39.46037099494098\n",
      "% of value of missing in CityLocation column is 7.546374367622259\n",
      "% of value of missing in Investorsname column is 0.33726812816188867\n"
     ]
    }
   ],
   "source": [
    "print(f\"% of value of missing in Investment column is {(null_count_df['index'=='3'][7]/len(df))*100}\")\n",
    "print(f\"% of value of missing in Remarks column is {(null_count_df['index'=='3'][9]/len(df))*100}\")\n",
    "print(f\"% of value of missing in IndustryVerical column is {(null_count_df['index'=='3'][3]/len(df))*100}\")\n",
    "print(f\"% of value of missing in subVertical column is {(null_count_df['index'=='3'][4]/len(df))*100}\")\n",
    "print(f\"% of value of missing in CityLocation column is {(null_count_df['index'=='3'][5]/len(df))*100}\")\n",
    "print(f\"% of value of missing in Investorsname column is {(null_count_df['index'=='3'][6]/len(df))*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc98e94",
   "metadata": {},
   "source": [
    "### Little's MCAR Test\n",
    "\n",
    "**Little's MCAR (Missing Completely at Random) Test** is a statistical test used to determine whether missing data in a dataset can be considered MCAR. The test checks if the missingness in the data is unrelated to both observed and unobserved variables, which is the assumption of MCAR.\n",
    "\n",
    "#### Key Points:\n",
    "- **Null Hypothesis (H₀)**: The data is MCAR (missing completely at random).\n",
    "- **Alternative Hypothesis (H₁)**: The data is not MCAR, implying that the missingness is related to other variables (MAR or MNAR).\n",
    "- **Test Output**: \n",
    "  - A p-value is produced. \n",
    "  - If the p-value is large (e.g., p > 0.05), we fail to reject H₀, meaning the data can be assumed to be MCAR.\n",
    "  - If the p-value is small (e.g., p < 0.05), we reject H₀, indicating the missing data is likely not MCAR.\n",
    "\n",
    "#### Usage:\n",
    "Little’s MCAR test helps to validate the assumption that data is missing at random, guiding decisions about how to handle missing data. If data is not MCAR, more complex imputation or modeling methods may be needed to address the missingness.\n",
    "\n",
    "**Limitations**: Little's MCAR test has reduced power with smaller sample sizes or large amounts of missing data, so results should be interpreted cautiously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fde8ec",
   "metadata": {},
   "source": [
    "### User-Defined Function for Little's MCAR Test\n",
    "\n",
    "The following user-defined function, `little_mcar_test(data)`, implements a basic version of **Little's MCAR Test** to determine whether missing data is Missing Completely at Random (MCAR).\n",
    "\n",
    "#### Function Breakdown:\n",
    "- **Input**: \n",
    "  - The function takes a dataset (`data`) as input. \n",
    "  - It checks for missing values in each column and creates binary masks where `1` represents a missing value and `0` represents a non-missing value.\n",
    "  \n",
    "- **Core Logic**: \n",
    "  - For each column with missing data, a mask is created. These masks are concatenated into a binary matrix `r`, where each row represents a sample and each column represents the missing pattern of a variable.\n",
    "  - The function computes the matrix product `r.T @ r` to summarize the missing patterns across columns.\n",
    "  - Using this, the **chi-squared statistic** (`chi2_stat`) is calculated as the trace of the matrix.\n",
    "  \n",
    "- **Degrees of Freedom**: \n",
    "  - The degrees of freedom (`df`) are calculated as `(n - 1) * m`, where `n` is the number of rows in the dataset, and `m` is the number of columns with missing data.\n",
    "\n",
    "- **Chi-Square Test**: \n",
    "  - The chi-squared test statistic and the degrees of freedom are used to compute the p-value (`p_value`), which helps determine if the data is MCAR.\n",
    "\n",
    "#### Output:\n",
    "- The function returns a dictionary containing:\n",
    "  - `chi2_stat`: The chi-squared test statistic.\n",
    "  - `degree_of_freedom`: Degrees of freedom for the test.\n",
    "  - `p_value`: The p-value used to assess whether the data is MCAR.\n",
    "\n",
    "#### Interpretation:\n",
    "- If the **p-value** is greater than a significance threshold (e.g., p > 0.05), the missing data can be considered **MCAR**.\n",
    "- If the **p-value** is small (e.g., p < 0.05), we reject the MCAR assumption, implying the missing data may not be random (MAR or MNAR).\n",
    "\n",
    "This custom function provides a straightforward way to test for the MCAR assumption, aiding in the analysis of missing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668a0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_mcar_test(data):\n",
    "    n = len(data)\n",
    "    groups = []\n",
    "    for col in data.columns:\n",
    "        mask = data[col].isnull()\n",
    "        if mask.any():\n",
    "            groups.append(mask.astype(int).values.reshape(-1,1))\n",
    "    if len(groups) == 0:\n",
    "        raise ValueError(\"No missing data found\")\n",
    "    r = np.concatenate(groups,axis=1)\n",
    "    group_stats = r.T @ r\n",
    "    m = len(groups)\n",
    "    df = (n-1) * m\n",
    "    chi2_stat = group_stats.trace()\n",
    "    p_value = chi2.sf(chi2_stat,df)\n",
    "    return {\"chi2_stat\":chi2_stat,\"degree_of_freedom\":df,\"p_value\":p_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8db5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic:3248\n",
      "Degrees of freedom:14226\n",
      "P-Value:1.0\n"
     ]
    }
   ],
   "source": [
    "result = little_mcar_test(df)\n",
    "print(f\"Chi-square statistic:{result['chi2_stat']}\")\n",
    "print(f\"Degrees of freedom:{result['degree_of_freedom']}\")\n",
    "print(f\"P-Value:{result['p_value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0efa2d",
   "metadata": {},
   "source": [
    "### Methods for Handling MCAR (Missing Completely at Random) Data\n",
    "\n",
    "When data is Missing Completely at Random (MCAR), the following methods can be used to handle missing values effectively:\n",
    "\n",
    "1. **List-wise Deletion**:\n",
    "   - In this method, any record with missing data in any of its variables is completely deleted from the dataset.\n",
    "   - This method is best suited when the percentage of missing data is very small (e.g., less than 2%).\n",
    "   - **Drawback**: It can lead to a significant reduction in the dataset size, especially when multiple variables have missing values.\n",
    "\n",
    "2. **Pair-wise Deletion**:\n",
    "   - Unlike list-wise deletion, pair-wise deletion only removes data when the specific pair of variables used in a statistical method has missing values.\n",
    "   - It works similarly to how a correlation matrix is calculated, where missing values are ignored between the two variables being analyzed.\n",
    "   - **Advantage**: This approach minimizes data loss as only the incomplete pairs are excluded from analysis, rather than entire records.\n",
    "   - **Use Case**: Pair-wise deletion is a better option when many variables in the dataset have missing values but different variables are missing across different cases.\n",
    "\n",
    "   **Key Difference**: \n",
    "   - List-wise deletion reduces the number of complete cases by removing entire rows, while pair-wise deletion adjusts the number of cases depending on the specific variables involved in the analysis.\n",
    "\n",
    "3. **Mean, Median & Mode Imputation**:\n",
    "   - This method involves replacing missing values with the mean, median, or mode of the respective variable.\n",
    "     - **Mean**: Best for continuous numerical data when the data is normally distributed.\n",
    "     - **Median**: Suitable when the data has skewness, as the median is less affected by outliers.\n",
    "     - **Mode**: Commonly used for categorical variables.\n",
    "   - **Advantage**: This is a simple and effective method that retains all records.\n",
    "   - **Drawback**: It may introduce bias into the dataset, especially if the underlying data distribution is complex.\n",
    "\n",
    "Each method has its trade-offs, and the choice depends on the amount and pattern of missing data, as well as the dataset's structure and analysis requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577906e5",
   "metadata": {},
   "source": [
    "### Columns to Apply List-wise Deletion\n",
    "\n",
    "- **Investment** (0.04% missing) and **Investorsname** (0.34% missing): \n",
    "  - Suitable for list-wise deletion since the missing percentage is very small, and it will not significantly impact the dataset size.\n",
    "  \n",
    "- **Remarks** (82.34%) and **SubVertical** (39.46%): \n",
    "  - Avoid list-wise deletion due to the high percentage of missing data. Consider using imputation methods instead.\n",
    "\n",
    "- **IndustryVertical** (7.21%) and **CityLocation** (7.55%): \n",
    "  - List-wise deletion could be applied, but since the missing percentage is moderate, imputation may be a better choice to minimize data loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d72762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0cb6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_cleaned = df2.dropna(subset=['InvestorsName','InvestmentType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4272d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          930\n",
       "CityLocation         179\n",
       "InvestorsName          0\n",
       "InvestmentType         0\n",
       "AmountInUSD            0\n",
       "Remarks             1945\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d4d88",
   "metadata": {},
   "source": [
    "### Imputation of Categorical Columns Using Mode\n",
    "\n",
    "For categorical columns with missing values, such as **Remarks**, **SubVertical**, **CityLocation**, and **IndustryVertical**, imputation using the **mode** is a suitable approach. The mode represents the most frequently occurring value in a dataset, making it a logical choice for filling in missing categorical data.\n",
    "\n",
    "#### Steps for Imputation:\n",
    "1. **Identify Categorical Columns**: Determine which columns are categorical and contain missing values.\n",
    "2. **Calculate Mode**: Use the mode function to find the most frequent value in each categorical column.\n",
    "3. **Impute Missing Values**: Replace missing values in these columns with their respective mode values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22a3780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "804906ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          936\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3777533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     NaN\n",
       "1                                     NaN\n",
       "2                                     NaN\n",
       "3                                     NaN\n",
       "4                                     NaN\n",
       "                      ...                \n",
       "2367                                  NaN\n",
       "2368                  Govt backed VC Fund\n",
       "2369                                  NaN\n",
       "2370    Strategic Funding, Minority stake\n",
       "2371                                  NaN\n",
       "Name: Remarks, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Remarks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2441c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "362763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = df3['Remarks'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e2d8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Remarks'] = df3['Remarks'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "075e6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                   0\n",
       "Date                  0\n",
       "StartupName           0\n",
       "IndustryVertical    171\n",
       "SubVertical         936\n",
       "CityLocation        179\n",
       "InvestorsName         8\n",
       "InvestmentType        1\n",
       "AmountInUSD           0\n",
       "Remarks               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0d7979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671c8419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Predictive Care Platform\n",
       "1                            Digital Marketing Agency\n",
       "2       Online platform for Higher Education Services\n",
       "3                              DIY Ecommerce platform\n",
       "4                       healthcare service aggregator\n",
       "                            ...                      \n",
       "2367                                              NaN\n",
       "2368                                              NaN\n",
       "2369                                              NaN\n",
       "2370                                              NaN\n",
       "2371                                              NaN\n",
       "Name: SubVertical, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['SubVertical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a615901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value_sub = df4['SubVertical'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a8c556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Online Pharmacy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_value_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca746e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['SubVertical'] = df4['SubVertical'].fillna(mode_value_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dc96643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical            0\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f2d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53b28b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bangalore\n",
       "1          Mumbai\n",
       "2       New Delhi\n",
       "3          Mumbai\n",
       "4       Hyderabad\n",
       "          ...    \n",
       "2367          NaN\n",
       "2368          NaN\n",
       "2369          NaN\n",
       "2370          NaN\n",
       "2371          NaN\n",
       "Name: CityLocation, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5['CityLocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58745645",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value_city = df5['CityLocation'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5180ae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangalore'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_value_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7682e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['CityLocation'] = df5['CityLocation'].fillna(mode_value_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f326bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          936\n",
       "CityLocation           0\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc0d7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5261cce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical     171\n",
       "SubVertical          936\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6388be03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Technology\n",
       "1              Technology\n",
       "2       Consumer Internet\n",
       "3       Consumer Internet\n",
       "4       Consumer Internet\n",
       "              ...        \n",
       "2367                  NaN\n",
       "2368                  NaN\n",
       "2369                  NaN\n",
       "2370                  NaN\n",
       "2371                  NaN\n",
       "Name: IndustryVertical, Length: 2372, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['IndustryVertical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92d7678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value_industry_verti = df6['IndustryVertical'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ec9410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consumer Internet'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_value_industry_verti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb26aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['IndustryVertical'] = df6['IndustryVertical'].fillna(mode_value_industry_verti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b47e9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                    0\n",
       "Date                   0\n",
       "StartupName            0\n",
       "IndustryVertical       0\n",
       "SubVertical          936\n",
       "CityLocation         179\n",
       "InvestorsName          8\n",
       "InvestmentType         1\n",
       "AmountInUSD            0\n",
       "Remarks             1953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
